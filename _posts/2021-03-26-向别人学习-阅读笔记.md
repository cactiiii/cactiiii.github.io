---
layout: my_post
categories: [paper translate]
---

## 前沿
终于又重新捡起来写点东西的习惯了，在此记录一下学到的可能有用的零碎知识。

* google recsys 2019 论文，他们用双塔模型+softmax做召回 [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/6c8a86c981a62b0126a11896b7f6ae0dae4c3566.pdf)
* 讲特征工程的blog:[推荐系统之特征构建](https://zhuanlan.zhihu.com/p/221783604)
* 阿里kdd 2019 优化embedding的文章，没有代码，偏理论, 感觉没啥实际意义 [Res-embedding for Deep Learning Based Click-Through Rate Prediction Modeling](https://arxiv.org/pdf/1906.10304.pdf)
* 字节2020不知道在哪里发的，讲召回模型：[Deep Retrieval: An End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/pdf/2007.07203.pdf)，文章内容较复古，含大量公式推导，没有源码。适合借鉴想法，不适合直接复用。
* google 2013在SIGMOD的论文：[Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41318.pdf)，讲如何将推荐日志与用户行为日志进行拼接，做的事情主要集中在保障可用性上，参考意义不大。而且文中只说了join好的点击日志如何输出，没说负样本是如何输出的。。
* facebook 2014年的论文，讲gbdt+lr的，模型本身已经过时了，但其中分享的一些数据方面的知识还挺有用的：[Practical Lessons from Predicting Clicks on Ads at Facebook](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)
    * 样本时效性越强，推荐效果越好，这是公认的事实。文中使用了一种叫做HashQueue的数据结构做样本拼接。
    * 在线学习需要做样本label监控，防止被攻击，这一点容易被大家忽视，当然优先级也比较低
    * 衍生出了Per-coordinate learning rate：Ad click prediction: a view from the trenches.
    * 衍伸出了Photon: Fault-tolerant and scalable joining of continuous data streams，google如何做样本拼接的
    * 特征的重要性也符合二八定律，少数特征贡献大部分的重要性
    * 历史类特征相比于上下文特征更重要。但是上下文特征对于冷启动场景是不可或缺的
    * 在均匀负采样实验中证明，样本越多效果越好
    * 负采样能够在减少样本规模的同时提升模型效果，具体原理猜测：（1）负样本有噪音（2）更好地学习了正样本。同时文中提出了简单换算公式进行ctr矫正。
* google 2013年kdd论文：[Ad Click Prediction: a View from the Trenches](https://www.researchgate.net/publication/262412214_Ad_click_prediction_a_view_from_the_trenches)
    * 提出了Per-coordinate learning rate，效果要比全局统一的learning rate好，具体原因是出现次数多的特征得到充分学习，学习率当然要小些，稀疏的特征在学习的早期学习率当然要大一些
    * 使用16 bit存小数，这个和阿里的COLD的思想类似，实现起来较困难。。。
    * 也提到了FTRL，然而它的原理至今没有弄懂
    * 负采样的作用是在不太影响效果的前提下降低样本量，采用了query级别的采样，配合样本权重设置，保证了梯度的期望保持不变，从而不会造成效果上大的影响
    * 如何评估模型效果？通过在不同的slicing上分析，可以看出模型更胜任哪些方面的工作，更不擅长哪些方面的工作，单纯看总的指标的话，容易忽略一些可发掘的细节
    * 对于ctr矫正，提出使用piecewise linear 方法，挺暴力的。应该是把数据分段，在每个小段上进行矫正
    * 使用特征hash没有收益。其实个人认为，没必要做特征hash啊
* 中科大2020年的综述性论文：Bias and Debias in Recommender System: A Survey and Future Directions
    * 显式反馈中，存在两种bias：selection bias、conformity bias
    * 隐式反馈中，也存在两种bias：exposure bias、position bias
    * 另外还有比较重要的bias：popularity bias unfairness
    * IPS(inverse propensity score)是一种简单普遍的方法
    * 或者可以单独建模，比如对于selection bias，单独首先建模用户会不会选择item的概率，再建模会给item打多少分。
    * 讲到解决方法的时候，跟说天书一样。通篇只记住两个词：IPS和casual model
    * 提到了RL可以用于解决EE问题
* facebook 2011年的论文：[The Anatomy of the Facebook Social Graph](https://arxiv.org/pdf/1111.4503.pdf)，主要是分析了下它的社交网络的一些属性
    * facebook有鼓励用户多形成好友关系的机制，触发条件是用户好友<=20
    * facebook对用户好友的上限设置为5000
    * 用户好友数的分布并不契合指数分布,这与经验不太相符
    * 好友之间的平均距离是4.7（比想象的要高一些）
    * 99%以上的用户存在于一个连通子图中
    * 提到了一个叫做local clustering coefficient的指标，个人感觉衡量好友关系的质量？
    * 人们更倾向于和年龄相仿的人成为好友，同一个国家的也一样。但是性别上没有明显区分。
* facebook 2013 kdd论文：[Representing Documents Through Their Readers](https://research.fb.com/wp-content/uploads/2016/11/representing-documents-through-their-readers.pdf)
    * 利用文章和分享文章的用户之间的关系，建立了文章到标签的一个映射，类似于主题模型，文章由词构成，每个标签也是由词构成。在视频推荐场景的参考意义不大
* linkedIn 2013 论文：[Structural Diversity in Social Recommender Systems](https://web.archive.org/web/20150919193706/http://ls13-www.cs.tu-dortmund.de/homepage/rsweb2013/papers/Huang.pdf)
    * 主要研究社交关系对用户活跃的影响
    * 参考文献中提到了比较多的社交推荐引用
    * 参考文件中提到，朋友关系/社区成员关系对社交网络推荐有比较大的影响;用户倾向于和一定数量的好友保持一致的行为
    * 此外，推荐的多样性也对推荐效果有影响，不同的文章分析的结论不一样。facebook的结论是推荐多样性能带来更多转化，进而提高好友的多样性，最终带来更多用户行为
    * 推荐系统是社交网络提升用户活跃和网络连接的工具
    * background部分没太看懂，需要后续研究下
    * 推荐的结构多样性如何衡量？通过三个指标：connected components(两两连接的最大子图)、triangle、average local node degree(节点的平均度数)
    * 结论是：推荐的结构多样性越低（connected components数量越少，triangle/average local node degree 越大）
    * 与facebook结论相反，分析原因是facebook应用场景更多是加入一个圈子，LinkedIn使用场景更多是在圈子内认识更多人
    * 用户的好友网络的结构多样性越高，用户越活跃
* PYMK: friend recommendation at myspace download 论文本身在网上找不到。。但是搜索它能搜到挺多后续的pymk方面的研究
* pymk方向2018的一篇论文：[Online Social Friend Recommendation Based on Multiple Social Network Correlation](http://www.ijatir.org/uploads/534621IJATIR16774-84.pdf)
    * 论文本身影响力不大，但是比较新
    * 推荐基于的数据有两大方向：基于拓扑和基于内容，个人理解：基于拓扑更多倾向pymk，基于内容更多倾向pyml
    * 隐私保护下的好友推荐（好友关系被视为敏感/隐私信息）
    * 文章本身价值不大，就是一篇水文。参考文献倒是可以帮助发现一些资源
* 流行度偏差方向2021年的论文，由腾讯联合大学发表：[Causal Intervention for Leveraging Popularity Bias in Recommendation](https://arxiv.org/pdf/2105.06067.pdf)
    * 流行度呈现长尾分布趋势，头部小部分item占据大部分的曝光位置。这种情况在模型训练-预测循环中又得到了放大。
    * 现有方法：Inverse Propensity Scoring（IPS），比较简单，效果一般；Causal Embedding，无法实施；Ranking Adjustment：启发式方法
    * 文章的假设：流行度分为两部分，一种是item内在属性带来的，这部分是可以加以利用的；另一部分是模型带来的，是需要加以遏制的
    * 推导过程很复杂，并且还使用了一些假设的东西。最终结论却挺简单：训练的时候，在原来模型预测的概率的基础上乘以m的r次方，就相当于考虑了流行度影响，然后预测的时候只使用模型预测的概率就可以消除流行度的负面影响
    * 往后就更扯了，预测的时候再乘上一个**预测的m的r次方**，这就成了利用了流行度的正面价值
    * 在实际使用上，这个和IPS的难度感觉相差不大
* 关于ANN
    * NN指Nearest Neighbor，ANN指Approximate Nearest Neighbor
    * NN的挑战不仅仅在于vector的维度比较高，也在于本身item的量比较大，两两之间都计算一次相似度然后取top的方法算得太慢，耗资源太多（spark也无能为力,总是OOM）
    * ANN中基于hash方法可以分为两种，一种是data-dependent的；另一种是data-independent，典型就是局部敏感哈希（Locality-Sensitive Hashing），可以有多个HashTable，每个HashTable可以有多个HashFunction
    * 可以用于各种去重与匹配：网页/文本/图像/音乐/指纹等
    * 重要的是hash function的选择，根据不同的距离定义，hash function也不一样
        * Jaccard distance：minhash。原始的minhash擅长解决两个item的Jaccard Distance的问题，更像是一种降维的方法，如果涉及到众多item，则需要在此基础上再做LSH
        * Cosine distance：sign(V*R)，其中R是一个随机向量。正是之前研究过的Annoy的实现，hashTable就是Annoy里的树的概念


