---
layout: my_post
categories: [paper translate]
---

## 前沿
终于又重新捡起来写点东西的习惯了，在此记录一下学到的可能有用的零碎知识。

* google recsys 2019 论文，他们用双塔模型+softmax做召回 [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/6c8a86c981a62b0126a11896b7f6ae0dae4c3566.pdf)
* 讲特征工程的blog:[推荐系统之特征构建](https://zhuanlan.zhihu.com/p/221783604)
* 阿里kdd 2019 优化embedding的文章，没有代码，偏理论, 感觉没啥实际意义 [Res-embedding for Deep Learning Based Click-Through Rate Prediction Modeling](https://arxiv.org/pdf/1906.10304.pdf)
* 字节2020不知道在哪里发的，讲召回模型：[Deep Retrieval: An End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/pdf/2007.07203.pdf)，文章内容较复古，含大量公式推导，没有源码。适合借鉴想法，不适合直接复用。
* google 2013在SIGMOD的论文：[Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41318.pdf)，讲如何将推荐日志与用户行为日志进行拼接，做的事情主要集中在保障可用性上，参考意义不大。而且文中只说了join好的点击日志如何输出，没说负样本是如何输出的。。
* facebook 2014年的论文，讲gbdt+lr的，模型本身已经过时了，但其中分享的一些数据方面的知识还挺有用的：[Practical Lessons from Predicting Clicks on Ads at Facebook](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)
    * 样本时效性越强，推荐效果越好，这是公认的事实。文中使用了一种叫做HashQueue的数据结构做样本拼接。
    * 在线学习需要做样本label监控，防止被攻击，这一点容易被大家忽视，当然优先级也比较低
    * 衍生出了Per-coordinate learning rate：Ad click prediction: a view from the trenches.
    * 衍伸出了Photon: Fault-tolerant and scalable joining of continuous data streams，google如何做样本拼接的
    * 特征的重要性也符合二八定律，少数特征贡献大部分的重要性
    * 历史类特征相比于上下文特征更重要。但是上下文特征对于冷启动场景是不可或缺的
    * 在均匀负采样实验中证明，样本越多效果越好
    * 负采样能够在减少样本规模的同时提升模型效果，具体原理猜测：（1）负样本有噪音（2）更好地学习了正样本。同时文中提出了简单换算公式进行ctr矫正。
* google 2013年kdd论文：[Ad Click Prediction: a View from the Trenches](https://www.researchgate.net/publication/262412214_Ad_click_prediction_a_view_from_the_trenches)
    * 提出了Per-coordinate learning rate，效果要比全局统一的learning rate好，具体原因是出现次数多的特征得到充分学习，学习率当然要小些，稀疏的特征在学习的早期学习率当然要大一些
    * 使用16 bit存小数，这个和阿里的COLD的思想类似，实现起来较困难。。。
    * 也提到了FTRL，然而它的原理至今没有弄懂
    * 负采样的作用是在不太影响效果的前提下降低样本量，采用了query级别的采样，配合样本权重设置，保证了梯度的期望保持不变，从而不会造成效果上大的影响
    * 如何评估模型效果？通过在不同的slicing上分析，可以看出模型更胜任哪些方面的工作，更不擅长哪些方面的工作，单纯看总的指标的话，容易忽略一些可发掘的细节
    * 对于ctr矫正，提出使用piecewise linear 方法，挺暴力的。应该是把数据分段，在每个小段上进行矫正
    * 使用特征hash没有收益。其实个人认为，没必要做特征hash啊
* 中科大2020年的综述性论文：Bias and Debias in Recommender System: A Survey and Future Directions
    * 显式反馈中，存在两种bias：selection bias、conformity bias
    * 隐式反馈中，也存在两种bias：exposure bias、position bias
    * 另外还有比较重要的bias：popularity bias unfairness
    * IPS(inverse propensity score)是一种简单普遍的方法
    * 或者可以单独建模，比如对于selection bias，单独首先建模用户会不会选择item的概率，再建模会给item打多少分。
    * 讲到解决方法的时候，跟说天书一样。通篇只记住两个词：IPS和casual model
    * 提到了RL可以用于解决EE问题
* facebook 2011年的论文：[The Anatomy of the Facebook Social Graph](https://arxiv.org/pdf/1111.4503.pdf)，主要是分析了下它的社交网络的一些属性
    * facebook有鼓励用户多形成好友关系的机制，触发条件是用户好友<=20
    * facebook对用户好友的上限设置为5000
    * 用户好友数的分布并不契合指数分布,这与经验不太相符
    * 好友之间的平均距离是4.7（比想象的要高一些）
    * 99%以上的用户存在于一个连通子图中
    * 提到了一个叫做local clustering coefficient的指标，个人感觉衡量好友关系的质量？
    * 人们更倾向于和年龄相仿的人成为好友，同一个国家的也一样。但是性别上没有明显区分。
* facebook 2013 kdd论文：[Representing Documents Through Their Readers](https://research.fb.com/wp-content/uploads/2016/11/representing-documents-through-their-readers.pdf)
    * 利用文章和分享文章的用户之间的关系，建立了文章到标签的一个映射，类似于主题模型，文章由词构成，每个标签也是由词构成。在视频推荐场景的参考意义不大
* linkedIn 2013 论文：[Structural Diversity in Social Recommender Systems](https://web.archive.org/web/20150919193706/http://ls13-www.cs.tu-dortmund.de/homepage/rsweb2013/papers/Huang.pdf)
    * 主要研究社交关系对用户活跃的影响
    * 参考文献中提到了比较多的社交推荐引用
    * 参考文件中提到，朋友关系/社区成员关系对社交网络推荐有比较大的影响;用户倾向于和一定数量的好友保持一致的行为
    * 此外，推荐的多样性也对推荐效果有影响，不同的文章分析的结论不一样。facebook的结论是推荐多样性能带来更多转化，进而提高好友的多样性，最终带来更多用户行为
    * 推荐系统是社交网络提升用户活跃和网络连接的工具
    * background部分没太看懂，需要后续研究下
    * 推荐的结构多样性如何衡量？通过三个指标：connected components(两两连接的最大子图)、triangle、average local node degree(节点的平均度数)
    * 结论是：推荐的结构多样性越低（connected components数量越少，triangle/average local node degree 越大）
    * 与facebook结论相反，分析原因是facebook应用场景更多是加入一个圈子，LinkedIn使用场景更多是在圈子内认识更多人
    * 用户的好友网络的结构多样性越高，用户越活跃
* PYMK: friend recommendation at myspace download 论文本身在网上找不到。。但是搜索它能搜到挺多后续的pymk方面的研究
* pymk方向2018的一篇论文：[Online Social Friend Recommendation Based on Multiple Social Network Correlation](http://www.ijatir.org/uploads/534621IJATIR16774-84.pdf)
    * 论文本身影响力不大，但是比较新
    * 推荐基于的数据有两大方向：基于拓扑和基于内容，个人理解：基于拓扑更多倾向pymk，基于内容更多倾向pyml
    * 隐私保护下的好友推荐（好友关系被视为敏感/隐私信息）
    * 文章本身价值不大，就是一篇水文。参考文献倒是可以帮助发现一些资源
* 流行度偏差方向2021年的论文，由腾讯联合大学发表：[Causal Intervention for Leveraging Popularity Bias in Recommendation](https://arxiv.org/pdf/2105.06067.pdf)
    * 流行度呈现长尾分布趋势，头部小部分item占据大部分的曝光位置。这种情况在模型训练-预测循环中又得到了放大。
    * 现有方法：Inverse Propensity Scoring（IPS），比较简单，效果一般；Causal Embedding，无法实施；Ranking Adjustment：启发式方法
    * 文章的假设：流行度分为两部分，一种是item内在属性带来的，这部分是可以加以利用的；另一部分是模型带来的，是需要加以遏制的
    * 推导过程很复杂，并且还使用了一些假设的东西。最终结论却挺简单：训练的时候，在原来模型预测的概率的基础上乘以m的r次方，就相当于考虑了流行度影响，然后预测的时候只使用模型预测的概率就可以消除流行度的负面影响
    * 往后就更扯了，预测的时候再乘上一个**预测的m的r次方**，这就成了利用了流行度的正面价值
    * 在实际使用上，这个和IPS的难度感觉相差不大
    * 好的地方是这篇文章带code：[链接](https://github.com/zyang1580/PDA)
* 关于ANN
    * NN指Nearest Neighbor，ANN指Approximate Nearest Neighbor
    * NN的挑战不仅仅在于vector的维度比较高，也在于本身item的量比较大，两两之间都计算一次相似度然后取top的方法算得太慢，耗资源太多（spark也无能为力,总是OOM）
    * ANN中基于hash方法可以分为两种，一种是data-dependent的；另一种是data-independent，典型就是局部敏感哈希（Locality-Sensitive Hashing），可以有多个HashTable，每个HashTable可以有多个HashFunction
    * 可以用于各种去重与匹配：网页/文本/图像/音乐/指纹等
    * 重要的是hash function的选择，根据不同的距离定义，hash function也不一样
        * Jaccard distance：minhash。原始的minhash擅长解决两个item的Jaccard Distance的问题，更像是一种降维的方法，如果涉及到众多item，则需要在此基础上再做LSH
        * Cosine distance：sign(V*R)，其中R是一个随机向量。正是之前研究过的Annoy的实现，hashTable就是Annoy里的树的概念
* 2018年关于cascade learning的论文：[Deep Cascade Learning](https://ieeexplore.ieee.org/ielx7/5962385/8495104/08307262.pdf)
    * cascade learning就是自下而上地逐层训练深度神经网络，这样每层训练的时候都离目标不远，不会有梯度消失的现象，因此能够在底层网络中学到更“健壮”的特征和过滤器（CNN专有）
    * 时间复杂度降低（因为会把上次训练的预测结果存储起来，下次直接用，不用再前向传播了），空间复杂度降低（网络比较大的时候，存储网络本身比存储上次训练的输出更占内存）
    * 算法的方差更小（观察到的现象），比传统方式更稳定，传统end-to-end训练更依赖初始化的好坏（方差大的后果）
    * 但是算法本身的偏差也更大，因此更适合作为一种预训练方案
* hinton 2015年的论文：[Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf)
    * bagging是一种简单的提升效果的方法，但是缺点是模型和计算量会比较大
    * 其实模型训练的目标和使用者的目标并不吻合。模型训练的目标是优化训练集上的指标，而真实目标是优化在新数据上的泛化性能。
    * 大模型预测的概率分布可以作为训练小模型的“软目标”
    * 所谓“蒸馏”，是指在softmax中引入了一个温度T,使用大模型训练小模型的时候，用一个比较大的T。原因是为了使大模型输出的概率分布更加平滑，否则有些概率比较小的分类的梯度就太小了，而这些分类的pxtr其实还是包含挺多重要信息的。
    * 小模型作预测的时候，T要设置回1
    * 在loss函数中加入一项与真实label的交叉熵损失，可以提高模型表现。但有两点需要注意：1 新加的损失权重得比较小 2 原来的损失要乘上T的平方（公式推导中假设问题T很高，logits的平均值是0)
    * 学多个大模型怎么学？直接搞可能还是成本太高，可以学一个general model，然后在它confuse的类的集合上（这个集合可能又多个）分别训练specialist model
    * 通过蒸馏，小模型能学到大模型如何泛化的知识
* hinton 1991年的论文：[Adaptive Mixture of Local Expert ](https://www.researchgate.net/publication/233806999_Adaptive_Mixture_of_Local_Expert)
    * 多个相同结构的expert,一个gating network，gating network的输出经过softmax后作为expert被选中的概率
    * 亮点是loss函数的改进：缓解了experts之间的合作，鼓励了竞争，从而模型倾向于每次只有少数个export被激活，原理是：当某个expert的loss小于所有expert loss的加权平均时，它的weight就会增长，反之亦然
* 阿里2021年召回：[Path-based Deep Network for Candidate Item Matching in Recommenders](https://arxiv.org/pdf/2105.08246.pdf)
    * 包含Direct Net，Trigger Net & Similarity Net，Bias Net
    * Bias Net 用来在训练时学position bias、temporal bias等的影响，预测时去掉（跟我之前的想法有点像，可惜啊）
    * 用TriggerNet、Similarity Net来分别学用户-互动item、互动item-目标item的关系，本质上来说是用用户的互动item作为用户的兴趣点，逐个计算与目标item之间的关联程度
    * 相比CF，能够引入用户属性作为特征，相比EBR，能够捕捉更多样的用户兴趣
    * loss 设计得挺有意思，首先是Trigger Net & Similarity Net的输出的构造，其次是预测的相似度如何转化为0～1之间的概率值，这个得看原文
    * 预测的时候怎么做？
        * 首先得先建个倒排，对每个item，先用规则划出一批候选，然后用Similarity Net打分，把前k个作为倒排value
        * 线上召回的时候，先取用户的互动item，用Trigger Net对这些item打分，保留前m个
        * 然后用m个互动item去查倒排，得到候选池，然后再用不包含bias net的相似度公式去算相似度（Direct Net在此过程生效）
* 阿里2018年模型esmm：[Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate](https://arxiv.org/pdf/1804.07931.pdf)
    * 在诸如 点击-转化 这种包含多个顺序步骤的场景中，如何准确预估点击率和转化率？
    * 点击率的预估比较经典。但转化率如何预估？首先必须在点击样本上进行训练，转化成功的是正样本，其他的是负样本。这样就带来了两个问题：
        * 如何使用？使用的时候如果在曝光样本上直接预测转化率，那么会有样本选择偏差，ssb(sample selection bias)
        * click的样本量比较少，导致训练cvr的样本比较稀疏
    * 因此文章提出了在曝光样本上ctr和ctcvr一起预测的MTL模型，cvr作为一个中间结果，与ctr相乘得到ctcvr，loss中只包括ctr和ctcvr
    * 在曝光样本上训练，解决了样本选择偏差的问题，同时配合共享embedding，缓解了cvr样本稀疏的问题
    * 也可以分别预测ctr和ctcvr，然后用的时候ctcvr/ctr得到cvr，但是这种小数的除法数值不稳定，cvr会有大于1的情况
* google brain 17年的论文：[SWISH: A SELF-GATED ACTIVATION FUNCTION](https://arxiv.org/pdf/1710.05941v1.pdf?source=post_page)
    * 提出了新的激活函数：swish，公式比较简单：x * sigmoid(x)
    * 灵感来源于使用sigmoid做gate，swish的这种方式作者称为self-gating
    * 还有个带参数beta的版本： 2x * sigmoid(beta * x)，通过控制beta超参，swish-beta相当于在y=x与relu之间的非线性插值(不太懂这个名词)
    * 用的时候学习率比用relu的时候稍小一点比较合适
    * swish的几个特性：无上界，有下界，非单调，光滑
        * 无上界：relu和swish都无上界，和sigmoid/tanh比起来，x>0的时候不会有饱和现象
        * 有下界：有下界意味着函数能起到正则化的作用，左极限为0意味着更强的正则化效果（可能是相比于只在0点附近为0的函数来说）
        * 非单调：swish在0点偏左的地方值为负，增加了表达能力，改善了梯度流(大意就是梯度不为0，就能产生非0的梯度,反向传播的时候不至于造成梯度消失),同时对于不同的初始化方法及学习率来说也更鲁棒
* [FITNETS: HINTS FOR THIN DEEP NETS](https://arxiv.org/pdf/1412.6550.pdf)
    * 提出了一个叫做 FitNet的网络，目的是通过模型压缩，把大模型压缩成窄而深的小模型，“深”保证了小模型的泛华性，“窄”的好处是运算量减小了
    * 基于Knowledge Distillation做的改进，KD的不足之处是：无法训练比teacher深得多的student
    * hint layer：teacher的中间层；guided layer：student的中间层；guided 和hint之间还有个regressor function，就是个全连接，用于调整layer size的。文中是做图片处理的，作者取了个巧，把regressor设计为了另一个卷积操作，减少了璨数量
    * 怎么训练的？teacher网络需要先训练好，然后先训练guided layer和hint layer的loss，然后再训练两个完整网络之间的loss，想法有点类似于级联学习
* facebook 17年的文章：[Language Modeling with Gated Convolutional Networks](https://arxiv.org/pdf/1612.08083.pdf)
    * github上找的一个实现（看着不一定正确）：[代码](https://github.com/anantzoid/Language-Modeling-GatedCNN/blob/d49161af7ba32c71516a27e9d2603c6364234a44/model.py#L59)
    * 搞的是个语言模型
    * 使用CNN来提取上下文信息，相比RNN来说，优点是便于并行计算，缺点是有最长上下文限制，但是作者说上下文用不着太长
    * 使用类似于LSTM中的输出门的机制，在CNN原本的输出层，支出了两条路径：一路是线性FC，一路是sigmoid(FC)，第二路称为output gate，然后两路输出结果进行element wise相乘。注意两路的FC的权重/偏置是独立的
        * 这种结构有什么优点？相比于第一路使用tanh作为激活函数的版本来说，求导后发现有一项不会有饱和现象，从而层数较深的情况下不会有梯度消失现象
    * 还使用了带bottleneck的resnet，以及adaptive softmax，以及weight normalization and gradient clipping
* 阿里20年论文：[Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space](https://cs.nju.edu.cn/zlj/pdf/CIKM-2020-Li.pdf)
    * 提出的模型叫做HMOE，是在MMOE基础上改进而来，主要是为了解决多市场如何更好地在一个模型中训练的问题
    * 在多市场的情况下，直接训练一个大模型忽略了不同市场间的差异性；直接训练N个独立的小模型又忽略了市场之间的相关性
    * 这是一个典型的多任务学习（MTL）问题，不同市场间使用相同的特征空间和label空间
    * 借鉴MMOE结构，在特征空间学习不同市场的差异性和相关性；使用堆叠的模型在label空间学习不同任务的联系；同时提出了一个反向传播的方法，避免上下两个模型不能一起训练的问题
    * moe包括expert network和gate network，其中gate network使用的是softmax;文中使用的IMMOE是在moe基础上为每个task又增加了独立的MLP塔
    * 在IMMOE上又stack了一个model，主要学习在label空间中的不同市场的关联,具体做法有点类似于moe，也是用一个gate网络输出权重序列，每个权重值i对应市场i对当前市场的重要程度,注意是单向的
    * 上下两个gate原理类似，但是一个是在特征空间的选择，一个是在label空间的选择
    * 学习的时候，如果上下两个模型分开学习，就无法online learning；如果直接一起学习，则上面的模型就无法学习到domain-specific知识（就是说不同市场其实又共享上面的模型了）
    * 解决方式是控制反向传播的梯度，只回传到对应的塔内，以及gate网络中
* google 2021年的论文：[Large Dual Encoders Are Generalizable Retrievers](https://arxiv.org/pdf/2112.07899.pdf)
    * 虽然是google的，但是感觉没说啥
    * 结论是对于双塔模型来说，仅仅增加模型的规模，不用增加最终的emb的大小，就可以提升召回指标，尤其是跨域（domain）的指标。（跨域是指在其他区域的数据上训练，在本区域的数据上评估）
    * 文章讨论的是NLP领域的召回，所以预训练对于模型来说提升也比较大
* 发现一个介绍系统设计的课程[链接](https://www.educative.io/courses/grokking-the-system-design-interview?affiliate_id=5749180081373184%2F)，系统设计是个人的短板之一，所以打算花点钱看一下
    * 好像找到了一个免费的拷贝：[链接](https://akshay-iyangar.github.io/system-design/grokking-system-design/system-design-problems/instagram.html)，cool！
* facebook 2021年的论文：Que2Search: Fast and Accurate Query and Document Understanding for Search at Facebook
    * 原来在facebook也有这种现象：离线提升5%，在线实验只有4%
    * 用了XLM模型来理解自然语言，这是个什么模型？要不要看一下？
    * 双塔模型主要用于embedding-based retrieval以及粗排模型，其实是比较类似的，最新的好像还有什么Siamese network与w&d相结合的手段。。
    * 双塔模型的负样本是不是也比较重要？
    * 每个塔其实都是几个base model的fusion，处理自然语言用XLM，处理图像用预训练的模型，然后使用simple attention fusion得到最终embedding。
    * 在simple attention fusion的基础上，还用了gradient blending，就是使用多个loss函数，增强模型鲁棒性（使模型学习到在某些base model失效的情况下如何工作）
    * 对于预训练的base model，采用了比较低的learning rate
    * 对于document tower，还支出了一个分类任务辅助训练，采用multi label cross entropy损失函数，与原任务形成了一个multi task learning
    * 样本是如何构造的？正样本是根据业务理解，设置了过滤规则的pair对：用户点击进入商品详情，并与卖家交谈。负样本分两部分，第一部分是batch内的其他document(注意这里的batch中一开始全是正样本),使用scaled multi-class cross-entropy loss(其实就是softmax)，第二部分是batch内选的最hard的一个负样本，使用margin rank loss，其中的关键是：1 scaled对于收敛起重要作用 2 第二阶段必须在第一阶段已经收敛后再开始
    * ANN召回不是万能的，可以配合业务理解添加一些策略，例如文中就设置了位置/社交/分类上的限制(所以说，不要羞于使用策略）
    * 还可以这样？部署的时候，首屏使用对ANN相对保守的参数，保延迟牺牲一些精度，第二屏开始使用正常的参数。这样据说显著降低了硬件资源的消耗
    * 召回是不是数量越多越好？不是，召回的数据多了以后，排序模型可能无法处理多出来的噪音item，原因是排序模型与召回模型的不一致问题（inconsistency），这也是一个研究方向
    * 模型的可解释性：使用attention weight看特征的重要性；feature ablation，即让某个feature对应的输入置为默认值，其他都不变，然后根据输出的变化来计算feature importance
    * 未完全明了的关键词：multi-label cross-entropy，multi-class cross entropy，gradient blending，deep sets fusion, feature ablation
* EM(expectation maximization)算法
    * 发现一篇介绍EM挺不错的short tutorial：[链接](https://www.lri.fr/~sebag/COURS/EM_algorithm.pdf)
    * 解决什么问题：有缺失数据或者隐变量（latent variable）的情况下的极大似然估计（Maximum Likelihood）
    * E步：根据数据集以及现阶段的参数估计缺失数据/隐变量；M步：在E步的基础上，假设缺失数据/隐变量已知，来最大化似然函数
    * 为什么不直接优化似然函数？两个原因：1是有时候需要估计缺失数据/隐变量；2是缺失数据/隐变量的先验知识能够提升优化的效率
    * 为什么能收敛？因为经过推导，每一轮迭代都能保证似然函数不跌，最终可能收敛到一个局部最优点（也可能是全局最优）
    * 还发现一篇介绍HMM上EM的[知乎文章](https://zhuanlan.zhihu.com/p/46160757)以及它的[参考文献](http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf)
    * 文中提到，其实EM可以被梯度下降或者牛顿法代替，但是EM简单，健壮，便于实现
    * 关于EM如何用于HMM，配合这个[wiki](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm)终于看懂了，其实算的是概率（相比于有监督下的统计频率来说）
* 2017年的meta-learning文章：MAML:[Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://proceedings.mlr.press/v70/finn17a/finn17a.pdf)
    * meta-learning是在一个task集合上训练一个模型作为初始化的参数，在新的task到来后，只需要少量梯度下降，即可快速收敛
    * 训练的时候每个task的训练数据会被分为support set和query set，support set用于第一次梯度下降，query set用于第二次梯度下降
    * 第二次梯度下降按道理说会涉及到海森矩阵的计算，作者说在使用relu作为激活函数的情况下，二阶偏导可能比较接近0，所以在第二次梯度下降中略去二阶偏导的计算，对效果影响不大，同时能节省计算量
* 2019年韩国的用MAML做推荐的文章：[MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation](https://arxiv.org/pdf/1908.00413.pdf)
    * 大体思路是借鉴MAML的，就是把MAML的思想用在推荐上，具体就是对于新用户来说，每个用户视为一个TASK
    * 但是MELU没有限制local update的步数，训练数据中用户实际消费了多少就update多少次，当然使用次数作为分母做了归一化
    * 仿照MAML的简化计算方式，没有考虑二阶偏导。但是模型参数分为embedding和dense两部分，local update的时候只update dense(说是假设用户和item本身在local update的时候都没变，只是用户的想法变了，这样的话训练会更稳定)
    * 在对新的用户请求进行推荐的时候，就先把训练好的embedding和dense拿过来，在用户已经有的消费序列上update一轮，然后再计算候选的score
    * 还提出了一个如何选择evidence candidates的方法：计算local update时dense上梯度矩阵的弗罗伯尼范数（就和向量的l2范数类似），值越大说明对用户喜好的区分度越大。（不明白为啥要对Loss做除以|Loss|的操作）
* 13年关于音乐推荐的论文：[Deep content-based music recommendation](https://proceedings.neurips.cc/paper/2013/file/b3ba8f1bee1238a2f37603d90b58898d-Paper.pdf)
    * 基于协同过滤的推荐有两个问题：冷启动问题；小众item推荐不准确问题；在音乐推荐场景中，item的分布符合幂定律，头部的少部分item占据多数的推荐次数，但是从item库的角度上看，长尾的item才是大多数item
    * 提到了两种把音乐映射为向量的方法：
        * 比较传统的：提取MFCC，使用K-means聚类，使用类的出现次数作为bag-of-words 表示，然后使用PCA降维，然后使用线性回归/MLP来预测latent factor（没太看懂）
        * 基于CNN的：先提取time-frequency表示（怎么提取的？），作为网络输入，然后使用CNN，但是为了加速训练，训练数据是采样的3秒片段
    * 总的来说没太看懂，是怎么通过训练得到latent factors的？也没代码。
* 阿里19年的论文mind：[Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/pdf/1904.08030.pdf)
    * 提出：用一个embedding代表用户无法捕捉用户的多元兴趣
    * DIN只适合做排序，不适合做召回吗？
    * 用户有多个向量，item只有一个，如何计算相似度？用了个max。。
    * dynamic routing一般要做3次，以收敛
    * 相比原始dynamic routing，做了3点改进：1 bilinear mapping matrix共享，因为用户行为长度是变长的，并且要保证向量空间的一致 2 初始的bij不能是0，否则由于matrix共享，capsule会变成同步的 3 用启发式的公式决定用户兴趣的长度
    * 训练的时候，使用了label-aware attention，query 是target item emb， key和value都是capsule emb，相当于还是搞成了一个emb，然后和item emb做sampled softmax
    * 预测的时候，因为是做召回，所以需要用到ANN，就用不了attention了，使用的score相当于是取了max
    * softmax前可以配合一个pow，其中底数p是超参数，p越小，softmax越平滑
* WSDM 上18年的论文：[Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding](https://arxiv.org/pdf/1809.07426.pdf)
    * 主要改进是对用户消费的item emb序列的处理方式：使用CNN来建模list的序，而不是sum。并且能够支持skip，其实就相当于把list中的某些item屏蔽掉了
    * 做法是先把list中的embedding堆叠成“图片”，然后通过建模“图片”上的local特征来建模list中序的特征
    * 学到一个新名词：temporal recommendation，说的是追求根据时间来精确推荐，比如早上才推咖啡，而不是晚上
    * 把用户的兴趣分为了两种，一种是整体兴趣，类似于比较固定的长期兴趣；一种是序列模式兴趣，类似于短期消费兴趣
    * filter分为两大类，horizontal和vertical
        * horizontal的filter 宽度和emb长度一样，高度是取几个不同的值，每次处理的都是连续的几个item，所以建模的是list中的多个item到label的关系(union-level)
        * vertial的filter高度和list长度一样，宽度却固定为1，window slide完后相当于得到了list中item id的权重合，与传统方法类似，捕捉的是point-level的序列模式（可能是因为与马尔可夫链类似，就是多了个加权合）
        * 区别是horizontal后面接了个max，vertical的却没接，说是因为vertical要保证粒度就是1个latent factor，为了理解起来比较符合常理吧
    * 两类filter的结果concat起来再过一个FC，就得到了卷积序列emb，就是短期兴趣的emb
    * 卷积序列emb再与用户的静态emb（长期兴趣）concat起来，再过一个FC
    * 损失函数设计得又新颖又复杂，类似于softmax又不是softmax，估计是因为只有正样本，所以必须设计为类似softmax的方式，训练的时候按1:3采负样本
    * 这种论文，对于推荐的假设是，这个模型训练好后，预测的时候，它既充当召回，也充当排序了，直接取分数最高的TOP N作为推荐结果了
* facebook 21年的论文：[PiRank: Scalable Learning To Rank via Differentiable Sorting](https://arxiv.org/pdf/2012.06731v2.pdf)
    * ltr是学习序，目标是例如NDCG等和序有关的metric。但是实际优化的时候由于NDCG对模型参数不可导，会将原优化问题转化为3类代理loss中的一种：pointwise，pairwise，listwise
    * ltr传统的方法举例：softrank，ranknet，lambdarank，neuralSort
    * 公式太复杂，看不懂，放弃。是基于neuralSort的优化，还是理解neuralSort吧
* yahoo 13年的论文：[CTR Prediction for Contextual Advertising: Learning-to-Rank Approach](http://chbrown.github.io/kdd-2013-usb/workshops/ADKDD/doc/wks_submission_4.pdf)
    * 在上下文广告的场景中，有的用户可能根本就不会看广告，所以没有正样本的request会从训练数据里剔除掉。所以数据怎么处理还是要结合业务来看。关键是这个结论要经过实验验证才能上。
    * hinge loss: max(0, 1 - y * py)，用于svm的loss，y取正负1
    * 分两阶段学习，第一阶段：用svm训练pairwise loss，第二阶段：将第一阶段的输出y，转换为 a\*y + b 后输入sigmoid函数，其中b和a作为超参数由validation set调整，以拟合目标ctr
    * 所以这种第一阶段用于优化auc，第二阶段用于拟合xtr的思路还是挺不错的，但是这个第二阶段还是有点粗糙了，xtr的准确性好像不如直接用LR拟合（当然auc是更好了）
* google 16年的论文：[Learning to Rank with Selection Bias in Personal Search](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45286.pdf)
    * ltr一开始应该是用在IR中，主要处理搜索的场景
    * 两个名词：web search即互联网搜索引擎；personnal search 即私人搜索，比如邮件搜索、文件搜索、app搜索等，候选集是用户私有的，互相不一样
    * position bias：位置越靠前天然的xtr越高（和item质量没关系）；quality bias：list整体的质量会影响用户行为（可能是整体质量高，用户就更爱点）
    * 我们要求解的问题其实是在query的理论空间中最小化loss，但是由于不清楚理论空间的分布，所以采用理论空间的一个均匀采样数据集，来优化这个数据集上的loss，以近似在理论空间中的loss
    * 对于pairwise loss来说，没有正样本的query是不起作用的，但把这些样本过滤掉的话会引入selection bias。本文中selection bias是position bias的倒数
    * 用IPW（Inverse Propensity Weight）的方法来消除bias，IPW应该是一种比较流行和直观的方法
    * IPW需要估计position bias，怎么估计？用随机打乱list的方式。。预估出来的position bias：b(i)，其实就等比于用户选择第i个item的概率
    * 对上面的position bias的一个优化：对query进行分类，每个类别里单独计算position bias
    * 对上面的segmented position bias又做了优化：直接用模型预测query在各个position 上的click rate。（google是不是就喜欢追求极致优化）
    * 相应的，离线评估的时候也要对公式加以改造，文中给MRR也乘上了1/b(i) 因子；同时还有个更高级的办法：在测试集中筛选出排序和模型排序一样的数据，再评估metric
    * 这篇文章根本就没讲LTR，其实就是搞debias的，有些地方真的是晦涩难懂，nmd
* 20年的论文：[Controlling Fairness and Bias in Dynamic Learning-to-Rank](https://www.ijcai.org/proceedings/2021/0655.pdf)
    * 原来ltr online learning也叫dynamic ltr?
    * ltr系统的bias问题：bias导致rich-get-richer(富者更富）问题，如果能消除bias，系统就能学到基于merit（item本身质量）的score；
    * ltr系统的unfairness问题：即使学到的score是无偏的，如果score代表的是item在整体用户上的流行度，而不是千人千面的，那么直接用这个score排序无疑对长尾用户/长尾视频来说是低效的
    * 垃圾论文，完全是拼凑出来的，记住这个会议：IJCAI，真是个傻逼
* 知识蒸馏19年的论文：[Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation](https://arxiv.org/pdf/1905.08094.pdf)
    * KD是一种模型压缩的方法，除此之外，还有lightweight networks design, pruning, quantization
    * 传统KD的两个问题：知识transfer的效率差，很少有student模型能好过teacher模型的；其次如何设计和训练一个好的teacher模型是比较费力的
    * 所以本文提出了一种自蒸馏（self distillation）。。。结果是训练时间短了（不需要两阶段训练了），精度还提高了
* 15年微软的论文：[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
    * 在图像领域，网络的深度越深，往往模型效果越好，但是越深的模型也越难训练，文中的模型深度竟然能达到100多层
    * 随着层数的增长，传统DNN/CNN会出现梯度消失/爆炸的问题，解决方式包括：normalized initialization(归一化初始化？）、batch normalization，能让数十层网络收敛
    * 解决了收敛的问题后，人们发现，随着层数的增长，模型的准确率不增反降（按理来说应该至少是平的），排除原因不是过拟合后，引出本文的目的就是训练深度残差网络
    * 为什么残差网络更容易训练？极端情况下，如果要学习的是一个恒等映射(identity mapping)，残差网络将残差函数学成0的难度，比FC学成恒等映射的难度，显然要低
* hinton 17年的胶囊网络的论文：[Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf)
    * 每个胶囊是一个vector，长度代表某个实体存在的概率，方向代表这个实体的某些属性
    * squash函数用于将capsule的输出vector的长度进行归一化，不改变其方向
    * 胶囊i对胶囊j的预测向量是i的输出向量与一个Wij矩阵的相乘
    * 胶囊j的输入向量是所有下面一层胶囊的预测向量的加权和，其中权重cij是由bij做softmax计算而来，bij是迭代计算的,每次迭代加上一个值：j的输出向量与i的预测向量的内积
    * 由于是多分类任务，loss函数采用对每个分类分别计算margin loss，然后求和的形式
* 讲ftrl的一篇[文章](https://github.com/wzhe06/Ad-papers/blob/master/Optimization%20Method/%E5%9C%A8%E7%BA%BF%E6%9C%80%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3(Online%20Optimization)-%E5%86%AF%E6%89%AC.pdf)
    * 有空再看
* kuaishou 21年的论文：[poso](https://arxiv.org/pdf/2108.04690.pdf)
    * 其实就是一个很细的gate机制，给每个节点/emb/expert做了一个gate，位置应该是在激活函数之后
    * 参数量增加了不到5%
    * 和ppnet好像。。
* google 15年的论文：[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)
    * 解决什么问题：每层网络的输入，都受前面所有层的参数所影响，越深的层，前面的参数的波动经过放大就会对输入造成越大的影响
    * 这样模型就得不断地去适应这种分布的变化，称之为covariate shift（协变量偏移）
    * 因此需要稳定每层输入的分布，现有的做法是使用Relu、初始化方法、调小学习率
    * 所以BN的优点首先是加速收敛，可以使用较大的学习率；其次它还有正则化的作用。。
    * 分两步：第一步对节点的激活值/logit，减去batch内统计的均值，除以根号下（方差+e），其中e是为了防止除以0；第二步是再乘以gama，加上beta，作为新的激活值，gama和beta是可学习的参数
    * 第一步保证了激活值/logit的分布（均值0，方差1），但是可能会损失一些拟合能力，第二步是对拟合能力的补充
    * 预测的时候怎么做？预测的时候节点的均值和方差是固定的值，采用训练的时候每个batch的均值和方差的期望，其中方差的期望是除以m-1而不是m
    * BN在论文中是放在激活函数之前的。。但是知乎上说有实验发现放在激活函数后面效果更好
    * 为什么会有正则化的效果？因为模型对样本的预测值不是确定的，和其他样本有关，是一个有一定随机性的值，这样的特性对于网络的泛化性有好处
* google 16年的论文：[Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)
    * bn的缺点：对于RNN不友好；batch size比较小时效果受限 
    * 为什么bn对RNN不友好？均值和方差得在每个step上分别计算，如果测试集中有个超出训练集的长度的数据，就有问题了
    * 直接在每一层的维度上计算统计均值和标准差，样本之间不再有依赖
    * 主要用在RNN模型上，均值和标准差每一个step单独计算，但rebias和resacle是step间共享的
* google 17年讲transformer的论文：[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
    * 所谓的RNN无法并行计算，是指单条样本内无法并行，对数据并行则没有影响
    * encoder-decoder模型，先把输入x1..xn转换为中间表示z1...zn，然后再输出y1...ym，区别于传统RNN
    * self-attention为啥要在softmax前除以根号下dk?因为当dk比较大的时候，内积的值也范围越大，可能使softmax梯度饱和，从而不好训练
    * multi-head attention，就是把Q K V先用W做个线性投影，再进行self-attention，有几个head就做几次这种操作，完事后在head维度上concat起来，并再线性投影回原始向量长度，注意这其中并没有激活函数
    * multi-head attention能够学习的是不同位置上不同表示子空间中的信息
    * 相比于RNN，transformer将任意两个位置的距离变为了O(1)
    * encoder block 包括一个multi head attention和一个feed forward，其中feed forward由两层组成，第一层用RELU，第二层没有激活函数
    * 编码向量使用了sin/cos函数，其特点是，相距一定距离的两个编码向量，可以表示为另一个的线性变换
* google 19年的bert：[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
    * 主要是预训练模型，然后在下游任务上fine tune
    * 预训练使用一种叫做"masked language model"的目标，就是随机mask掉一些词，然后使用上下文来预测之，预测的模型结构是使用最终输出的mask词的hidden vector，接一个softmax
    * 但是这样会有个问题：预测的时候可没有[mask]这个token，所以也不是每次都替换为[mask]，10%概率随机挑个token，10%概率不变
    * 预训练还使用了句子级别的预测辅助训练，做法是对于问答对，随机生成一些负样本，然后使用[cls]的hidden vector做预测
    * 对于问答对这种训练数据，是用[sep]拼接成一条样本训练的，同时还给每个token加了个position embedding，以及segment embedding(用于标识是问句的token还是答句的token)。。
    * 模型结构只用了transformer的encoder
    * 如果要预测的是一个段落中的某个子句子怎么办？增加两个embedding，s和e，某个词是子句开始的概率就是s与它的hidden vector的内积，后面再接个softmax。候选子句的score就是s**ti + e**tj
    * ablation study发现模型越大效果越好。
* 广告流量分配算法1:[HMW（High Water Mark Algorithm）](https://zhuanlan.zhihu.com/p/123187987)
    * 是一种贪心的启发式算法，不保证最优解
    * 分为离线和在线两部分：离线部分确定广告的分配顺序和分配概率，在线部分是用户到来后，根据分配顺序对候选广告进行排序，根据分配概率决定是否出该广告
    * 离线部分中，先根据满足广告要求的流量大小由小到大排序，按照这个顺序计算ai，ai的要求是当前广告按照这个概率选的话刚好能满足要求
    * 在线部分中根据候选广告的概率和，如果超过1的话就需要对候选广告做截断，保证总和==1
    * 算法的缺点是什么？对流量预估比较敏感；没有考虑分配过程中可能某个GD广告的流量不够用了的情况；广告的重要程度没有加以区分
* yahoo 12年的流量分配算法：[SHALE: An Efficient Algorithm for Allocation of Guaranteed Display Advertising](https://arxiv.org/pdf/1203.3619.pdf)
    * 和HWM类似，也是基于二部图，优化一个带约束的目标函数
    * 目标函数由两部分组成：penalty和representativeness，penalty是每个contract的欠发(underdelivery)的加权和；representativeness是xij与thetaij的加权L2距离，thetaij的定义只与contract j有关，是contract j的demand与所有可用流量的比值，就是说contract j等比例取的话，从每个可用的supply 节点要取多少流量(impression)。加权项则考虑了supply节点的impression数量si、contract j的权重Vj、以及thetaij的倒数（一个contract越容易被满足，权重越低）
    * 限制条件是什么？每个contract的分发数量加上欠发数量必须大于等于dj；每个supplynode的分发概率的和必须小于等于1；xij uj都>=0
    * 上面说的都是离线部分，离线部分通过优化带约束的目标函数，给每个contract计算一个O(1)的值，在线serving的时候，就只使用保存的这个annotation来决定给当前用户分发什么，所以在线部分的目标是：计算又要快，又要尽可能接近离线时的解
* microsoft 21年的召回论文：[Multi-Interest-Aware User Modeling for Large-Scale Sequential Recommendations](https://arxiv.org/pdf/2102.09211.pdf)
    * 用户的兴趣可能是多维的，这时候用单一的embedding代表用户就很难代表多维的兴趣
* google deepmind 14年的论文：[Neural Turing Machines](https://arxiv.org/pdf/1410.5401.pdf)
    * 神经图灵机？
    * controller负责对外部的输入和输出，并依赖read heads和write heads从memory中读和写
    * memory是一个N\*M的矩阵，N是内存的位置的个数，M是每个位置的向量的长度；读和写并不是固定在某个位置，而是一个权重的分布
    * 读操作就是read head输出一个长度为N的权重向量，然后根据权重计算出的memory中的向量的加权和
    * 写操作包括两部分：清除和加，清除是给一个长度为M的erase vector，然后memory中的vector按照addressing的权重决定是否清除为0；加也类似，给一个长度为M的add vector，按照权重决定加多少
    * addressing包括两大步：基于内容的寻址和基于位置的寻址。基于内容的寻址就是两个vector计算相似度，再接一个带松弛变量的softmax；基于位置的寻址在前面的基础上又做了3个步骤：interpolation，就是和上一步的权重做个加权平均，然后是rotation，具体也是由controller先生成一个rotation的分布，然后求加权和，最后是sharpen，就是在上一步的值的基础上取个lambda次幂，然后softmax
    * controller可以是MLP，也可以是LSTM
* tencent 20年做MTL的PLE
    * negative transfor: 可能是说关联性不大的任务，一起训练的话，会互相伤害
    * seesaw phenomenon：跷跷板现象，某些任务指标涨，代价是其他任务指标跌，文章主要解决这个问题
    * share botoom 的一个缺点是：底层参数直接共享，可能会有任务之间冲突的现象
    * PLE显式地区分了共享参数和任务独享expert; expert和gate有多层，学习更抽象的表达; 渐进式的路由来建模expert之间的交互
    * mmoe的缺点：共享所有expert，对于某些任务可能不太友好；expert之间没有交互，限制表达能力
    * shared expert 和 specific epert如何融合？和mmoe一样，就得到了CGC
    * 把CGC进行多层堆叠就得到了PLE，其中每一层的输出是啥？每个task就输出一个vector，而共享的experts也组成了一个虚拟的task，它的输入是下面所有的expert（共享的和独有的），这样做，估计是为了能更好地提取高阶的交互特征吧
    * loss函数的设计：不在样本空间的loss不计算
    * task loss weight:启发式的方法，人为给个初始权重，随着epoch增加越来越小
* google 19年的论文：[Fairness in Recommendation Ranking through Pairwise Comparisons](https://arxiv.org/pdf/1903.00780.pdf)
    * 提到的fairness，主要分为两种：item group内的公平性和item group间的公平性
    * item group内的公平性是指，对于不同的group来说，点击样本排在未点击样本前面的概率是相同的。就是说模型没有把某些group学的好，某些学的差。
    * item group间的公平性是指，group1的整样本，是否能排在group2的负样本的前面。这个是为了防止某些group整体被低估
    * 如何测量一个推荐系统的fairness？不能用现有数据，因为会有推荐模型先天的bias存在。采用的是单独划分一批随机流量的方式，每次随机选两个item放在第二和第三个的位置。最后统计概率的时候，使用的是那些有一个点击的pair对。
    * 最后解决方式是，往训练目标中加一个正则项，用来优化随机流量中的一个启发式loss。参考价值不大。
    * 不是说google的论文就是好的，也要看发表在哪个会议上。。
* JD 2020年的论文：[Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems](https://drive.google.com/file/d/13DGxZyz2G_Tli23xvW5wscgxuEKB8xc9/view)(有代码)
    * 除了position bias，还提出了一个neighboring bias，就是说item展示时候的上下文也会影响item的ctr，具体就是如果上下文都是比较类似的item的话，click会被分散，ctr也就低了
    * 使用多个transformer来建模用户的不同的行为序列，比只建模click行为序列要好。与之前的理解不一样的是，不止用了encoder，还用了decoder，decoder部分用的是target item做的attention
    * 使用单独的bias网络来解决bias问题，通过将位置/上下文输入给MLP，计算propensity score(实际就是经过relu激活函数后的一个值),最后和输出xtr的sigmoid之前的值相加
    * 当然，预测的时候是不应该使用bias网络的输出的。。
    * 最终发现上下文输入给bias网络有明显效果，位置信息输入进去没啥效果，所以TA用的时候只用了上下文信息
    * 如何处理sequence里的位置信息？用原始attention启发式的sin cos函数编码位置信息；或者直接学习pos emb，然后用加法。文中实验表明后者效果更好一些
* google 21年的论文：[Self-supervised Learning for Large-scale Item Recommendations](https://arxiv.org/pdf/2007.12865.pdf)
    * 推荐系统中，item的曝光量分布符合幂律分布，长尾的item往往label比较稀疏，模型学习得也不够充分，本文主要解决这个问题
    * 自监督学习，是先通过数据增强的方式生成额外的样本，然后添加辅助任务，在其中监督模型预测或重构原始样本,从而提升表示学习的质量。好处是不需要额外收集label
    * 文中将自监督学习加以改进，使之能够处理推荐系统中的稀疏特征，然后使用对比学习的loss指导自监督网络在增强数据上的学习，来提升item侧长尾embedding的质量
    * 对比学习的英文是什么？contrastive learning
    * 数据增强是什么做的？当然文中主要是每次每个item通过数据增强会生成两个新的item，所以数据增强主要是把特征分为两个互补集合
        * 一种简单方法是对特征集合做随机的mask，对于一次能取多个值的id类特征，再额外每次随机drop掉几个值
        * 改进的方法是考虑特征之间的互信息（当然是离散特征），每次随机取一个特征，然后从剩下的特征中取互信息最大的topN作为一个集合，剩下的特征自然是另一个集合
    * 数据增强的样本如何取？
        * 直接从训练数据中取原始样本，会收到线上幂律分布的影响，导致还是关注头部item。因此文章采用从索引中随机抽取的方式
    * 如何构造自监督学习网络？
        * 通过数据增强，从item生成item1和item2的特征后，item1和item2输入自监督网络的两个塔中，这两个塔的embedding层共享，并且与主网络的embedding没有关系；而这两个塔的MLP共享，并且与主网络的item侧塔MLP也是共享的
        * 所以主要就是要帮助学习主网络item侧塔的MLP
    * loss如何构造的
        * loss就是在每次从索引随机取的item集合上，对每个item1，认为item2是正样本，其他原始样本的item2是负样本，然后使用带温度的softmax计算loss，然后求和
* NIPS会议上17年的论文：[DropoutNet: Addressing Cold Start in Recommender Systems](https://www.cs.toronto.edu/~mvolkovs/nips2017_deepcf.pdf)
    * 冷启动问题其实等价于交互label缺失问题
    * 文章的思路是，既然冷启动样本比较少，那就认为构造一些输入，是在原始输入的基础上，人为去掉一些输入的信息，相当于是一种样本增强，最终增强了模型的泛化性，提升冷启表现
    * 将用户和item的特征分为了两部分：基于label计算出来的偏好embedding（我理解其实就是类似于矩阵分解的embedding）和基于内容计算出来的embedding
    * 两部分embedding先分别过两个塔，转换成两个更高阶的embedding，然后拼接起来再送入MLP，最终得到user/item侧embedding
    * 作者认为本来用偏好embedding就可以，但是由于冷启动问题的存在，对于新用户/新物品要强迫模型能从内容中计算出一个相对比较好的与偏好embedding相似的embedding，所以模型学习的目标是，让上一步中最终得到的embeding的内积，与用户/item的原始偏好embedding的内积尽量接近（mse loss）
    * 样本从哪儿来？是随机采样的用户-item对，解决新用户问题时，将网络输入中用户偏好embedding置0；新item问题类似。
    * 训练好后怎么用？因为文章中说模型要应用在从冷启到成熟的各个阶段，所以不能直接说对于新用户只用内容embedding，文章中用的时候对所有用户都输入了偏好embedding和内容embedding，融合的事交给模型做，而纯新用户没有偏好embedding的时候，就用交互过的item embedding的均值来近似
    * 这样就引出了另一个问题：训练时候的随机样本，应该再增加一种处理方式：用户的label embedding由交互过的item embedding均值代替，或者item的label embedding由交互过的user embedding均值代替
* 18年的论文：[Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics](https://arxiv.org/pdf/1705.07115.pdf)
    * 讲的是MTL如何设置不同任务的loss的权重，loss设置得好的话，每个任务都可能会比单独训练还要好
    * 但是手动搜索最优的权重的话时间成本会比较高
    * 出发点是为每个任务引入了一个噪声参数delta，是一个可训练的参数，经过推导后发现，delta可以被认为是给task的loss增加了一个权重
    * 具体是每个task的loss增加权重：1/(delta^2)，loss再加上一项：log(delta)。其中后面的一项可以认为是起正则化的作用，否则的话delta会被学的很大。
    * 实际训练的时候，如果delta为0怎么办？作者做了一下转化：s=log(delta^2)，模型学习s，用的时候1/(delta^2)就成了1/exp(s)，log(delta)就成了s/2
* 介绍ANN综述的一篇博客：[https://flashgene.com/archives/92711.html](https://flashgene.com/archives/92711.html)
    * 常用的ANN方法其实可以分为几类：基于树的；基于LSH（局部敏感哈希）的；基于聚类-倒排的；基于HNSW的
    * 之前用的Annoy，其实是基于树的一种方法，kd-tree也是基于树的
    * LSH的话，对于不同的距离度量使用的是不同的hash函数：cos使用SIGN(V*R);欧几里得距离使用|V*R-a|/b。其中R是随机向量，b是桶宽，a是[0-a]的随机数。具体可见[链接](https://flashgene.com/archives/92711.html)
    * faiss里支持倒排的方法，就是先用kmeans聚类，然后构建聚类中心->向量id的映射，好处是不用存储向量vector
    * HNSW方法其实是最优的，也最复杂
