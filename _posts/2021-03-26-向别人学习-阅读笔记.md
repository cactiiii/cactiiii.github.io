---
layout: my_post
categories: [paper translate]
---

## 前沿
终于又重新捡起来写点东西的习惯了，在此记录一下学到的可能有用的零碎知识。

* google recsys 2019 论文，他们用双塔模型+softmax做召回 [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/6c8a86c981a62b0126a11896b7f6ae0dae4c3566.pdf)
* 讲特征工程的blog:[推荐系统之特征构建](https://zhuanlan.zhihu.com/p/221783604)
* 阿里kdd 2019 优化embedding的文章，没有代码，偏理论, 感觉没啥实际意义 [Res-embedding for Deep Learning Based Click-Through Rate Prediction Modeling](https://arxiv.org/pdf/1906.10304.pdf)
* 字节2020不知道在哪里发的，讲召回模型：[Deep Retrieval: An End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/pdf/2007.07203.pdf)，文章内容较复古，含大量公式推导，没有源码。适合借鉴想法，不适合直接复用。
* google 2013在SIGMOD的论文：[Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41318.pdf)，讲如何将推荐日志与用户行为日志进行拼接，做的事情主要集中在保障可用性上，参考意义不大。而且文中只说了join好的点击日志如何输出，没说负样本是如何输出的。。
* facebook 2014年的论文，讲gbdt+lr的，模型本身已经过时了，但其中分享的一些数据方面的知识还挺有用的：[Practical Lessons from Predicting Clicks on Ads at Facebook](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)
    * 样本时效性越强，推荐效果越好，这是公认的事实。文中使用了一种叫做HashQueue的数据结构做样本拼接。
    * 在线学习需要做样本label监控，防止被攻击，这一点容易被大家忽视，当然优先级也比较低
    * 衍生出了Per-coordinate learning rate：Ad click prediction: a view from the trenches.
    * 衍伸出了Photon: Fault-tolerant and scalable joining of continuous data streams，google如何做样本拼接的
    * 特征的重要性也符合二八定律，少数特征贡献大部分的重要性
    * 历史类特征相比于上下文特征更重要。但是上下文特征对于冷启动场景是不可或缺的
    * 在均匀负采样实验中证明，样本越多效果越好
    * 负采样能够在减少样本规模的同时提升模型效果，具体原理猜测：（1）负样本有噪音（2）更好地学习了正样本。同时文中提出了简单换算公式进行ctr矫正。
* google 2013年kdd论文：[Ad Click Prediction: a View from the Trenches](https://www.researchgate.net/publication/262412214_Ad_click_prediction_a_view_from_the_trenches)
    * 提出了Per-coordinate learning rate，效果要比全局统一的learning rate好，具体原因是出现次数多的特征得到充分学习，学习率当然要小些，稀疏的特征在学习的早期学习率当然要大一些
    * 使用16 bit存小数，这个和阿里的COLD的思想类似，实现起来较困难。。。
    * 也提到了FTRL，然而它的原理至今没有弄懂
    * 负采样的作用是在不太影响效果的前提下降低样本量，采用了query级别的采样，配合样本权重设置，保证了梯度的期望保持不变，从而不会造成效果上大的影响
    * 如何评估模型效果？通过在不同的slicing上分析，可以看出模型更胜任哪些方面的工作，更不擅长哪些方面的工作，单纯看总的指标的话，容易忽略一些可发掘的细节
    * 对于ctr矫正，提出使用piecewise linear 方法，挺暴力的。应该是把数据分段，在每个小段上进行矫正
    * 使用特征hash没有收益。其实个人认为，没必要做特征hash啊
* 中科大2020年的综述性论文：Bias and Debias in Recommender System: A Survey and Future Directions
    * 显式反馈中，存在两种bias：selection bias、conformity bias
    * 隐式反馈中，也存在两种bias：exposure bias、position bias
    * 另外还有比较重要的bias：popularity bias unfairness
    * IPS(inverse propensity score)是一种简单普遍的方法
    * 或者可以单独建模，比如对于selection bias，单独首先建模用户会不会选择item的概率，再建模会给item打多少分。
    * 讲到解决方法的时候，跟说天书一样。通篇只记住两个词：IPS和casual model
    * 提到了RL可以用于解决EE问题
